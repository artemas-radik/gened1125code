The code is in gen.py. Note that it makes reference to a local server. This server is provided by the https://lmstudio.ai software, and is utilizing the Meta-Llama-3-8B-Instruct-GGUF model (https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF). To get this to run locally either use a high-end GPU or tune down the parameters significantly (i.e. decrease number of iterations).